# FunctionGemma Fine-Tuning for OpenShift Commands

Fine-tune Google's FunctionGemma (270M parameters) to convert natural language into OpenShift/Kubernetes CLI commands.

![Python](https://img.shields.io/badge/Python-3.10+-blue)
![License](https://img.shields.io/badge/License-Apache%202.0-green)
![GPU](https://img.shields.io/badge/GPU-Optional-orange)

## ğŸ¯ What This Does

**Input:** "Show me all running pods"  
**Output:** `oc get pods`

## âœ¨ Features

- ğŸ¤– Fine-tunes Google's FunctionGemma (270M params)
- âš¡ Uses LoRA - trains only 0.14% of parameters
- ğŸ–¥ï¸ Works on CPU or GPU
- ğŸ“¦ Tested on Red Hat OpenShift AI
- ğŸ”§ Includes GPU driver fix for CUDA 13

## ğŸ“‹ Prerequisites

- Python 3.10+
- HuggingFace account ([accept Gemma license](https://huggingface.co/google/functiongemma-270m-it))
- 8GB RAM minimum
- GPU optional (training takes ~2 min on GPU, ~15 min on CPU)

## ğŸš€ Quick Start

### 1. Clone and Install

```bash
git clone https://github.com/yourusername/functiongemma-finetuning.git
cd functiongemma-finetuning
pip install -r requirements.txt
```

### 2. Login to HuggingFace

```python
from huggingface_hub import login
login(token="YOUR_HF_TOKEN")
```

### 3. Run Training

```bash
python finetune_functiongemma.py
```

## ğŸ”§ GPU Driver Fix (OpenShift AI)

If you get `Error 803: unsupported display driver`, add this before importing torch:

```python
import ctypes
ctypes.CDLL('/lib64/libcuda.so.1', mode=ctypes.RTLD_GLOBAL)

import torch  # Now CUDA works!
```

## ğŸ“Š Results

| Command Type | Accuracy |
|--------------|----------|
| Get resources (pods, services, nodes) | âœ… High |
| Scale deployments | âš ï¸ Medium |
| Complex commands | âŒ Needs more training |

**Overall Accuracy:** 33% (with 52 training examples)

## ğŸ“ Project Structure

```
functiongemma-finetuning/
â”œâ”€â”€ README.md                    # This file
â”œâ”€â”€ BLOG.md                      # Detailed blog post
â”œâ”€â”€ ISSUES.md                    # Problems and solutions
â”œâ”€â”€ finetune_functiongemma.py    # Training script
â”œâ”€â”€ training_data.json           # Training examples
â””â”€â”€ requirements.txt             # Dependencies
```

## ğŸ”§ Supported Commands

| Natural Language | OpenShift Command |
|-----------------|-------------------|
| list pods | `oc get pods` |
| show deployments | `oc get deployments` |
| get services | `oc get services` |
| get nodes | `oc get nodes` |
| show namespaces | `oc get namespaces` |
| get routes | `oc get routes` |
| get events | `oc get events` |
| get secrets | `oc get secrets` |

## ğŸ“ˆ Training Stats

| Metric | Value |
|--------|-------|
| Base Model | google/functiongemma-270m-it |
| Total Parameters | 268,835,456 |
| Trainable (LoRA) | 368,640 (0.14%) |
| Training Time (GPU) | ~2 minutes |
| Training Time (CPU) | ~15 minutes |
| Training Examples | 52 |

## âš ï¸ Common Issues

See [ISSUES.md](./ISSUES.md) for solutions to:

- GPU driver mismatch (Error 803)
- Transformers version errors
- Model outputting pad tokens
- Loss going to 0

## ğŸ§ª Testing

```python
peft_model.eval()

input_text = "User: list pods\nCommand:"
inputs = tokenizer(input_text, return_tensors="pt").to("cuda")

outputs = peft_model.generate(**inputs, max_new_tokens=30, do_sample=False)
print(tokenizer.decode(outputs[0], skip_special_tokens=True))
# Output: User: list pods
#         Command: oc get pods
```

## ğŸ”— Resources

- [Google FunctionGemma Docs](https://ai.google.dev/gemma/docs/functiongemma)
- [HuggingFace Model](https://huggingface.co/google/functiongemma-270m-it)
- [LoRA Paper](https://arxiv.org/abs/2106.09685)
- [PEFT Documentation](https://huggingface.co/docs/peft)
- [Red Hat OpenShift AI](https://www.redhat.com/en/technologies/cloud-computing/openshift/openshift-ai)

## ğŸ“ License

This project is for educational purposes. Uses Google's Gemma model which requires accepting the [Gemma Terms of Use](https://ai.google.dev/gemma/terms).

## ğŸ¤ Contributing

Contributions welcome! Ideas:
- Add more training examples
- Support kubectl commands
- Build a web interface
- Try larger models

## ğŸ‘¤ Author

**Nirjhar Jajodia**

Created while learning AI/ML on Red Hat OpenShift AI.

---

â­ Star this repo if you found it helpful!
